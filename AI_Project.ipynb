{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "train = pd.read_csv(\"kidney_train.csv\")\n",
    "test = pd.read_csv(\"kidney_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X226496_at</th>\n",
       "      <th>X219563_at</th>\n",
       "      <th>X208383_s_at</th>\n",
       "      <th>X220082_at</th>\n",
       "      <th>X225809_at</th>\n",
       "      <th>X206339_at</th>\n",
       "      <th>X227889_at</th>\n",
       "      <th>X210754_s_at</th>\n",
       "      <th>X232964_at</th>\n",
       "      <th>X223609_at</th>\n",
       "      <th>...</th>\n",
       "      <th>X209987_s_at</th>\n",
       "      <th>X225866_at</th>\n",
       "      <th>X219017_at</th>\n",
       "      <th>X225011_at</th>\n",
       "      <th>X214612_x_at</th>\n",
       "      <th>X213699_s_at</th>\n",
       "      <th>X225155_at</th>\n",
       "      <th>X1560500_at</th>\n",
       "      <th>X212337_at</th>\n",
       "      <th>X223206_s_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663.3</td>\n",
       "      <td>517.1</td>\n",
       "      <td>11077.7</td>\n",
       "      <td>429.9</td>\n",
       "      <td>342.0</td>\n",
       "      <td>386.1</td>\n",
       "      <td>391.4</td>\n",
       "      <td>588.9</td>\n",
       "      <td>1346.1</td>\n",
       "      <td>82.6</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>1521.9</td>\n",
       "      <td>581.3</td>\n",
       "      <td>1713.9</td>\n",
       "      <td>137.5</td>\n",
       "      <td>17556.8</td>\n",
       "      <td>9184.4</td>\n",
       "      <td>648.6</td>\n",
       "      <td>2215.1</td>\n",
       "      <td>593.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1747.1</td>\n",
       "      <td>343.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>181.6</td>\n",
       "      <td>432.2</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1347.7</td>\n",
       "      <td>931.0</td>\n",
       "      <td>1693.5</td>\n",
       "      <td>173.9</td>\n",
       "      <td>...</td>\n",
       "      <td>88.1</td>\n",
       "      <td>1793.9</td>\n",
       "      <td>661.1</td>\n",
       "      <td>2142.9</td>\n",
       "      <td>46.3</td>\n",
       "      <td>19301.6</td>\n",
       "      <td>15380.4</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>2670.4</td>\n",
       "      <td>969.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1738.1</td>\n",
       "      <td>5589.2</td>\n",
       "      <td>4701.2</td>\n",
       "      <td>129.3</td>\n",
       "      <td>1105.4</td>\n",
       "      <td>59.8</td>\n",
       "      <td>1007.4</td>\n",
       "      <td>1165.6</td>\n",
       "      <td>1174.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1206.1</td>\n",
       "      <td>705.9</td>\n",
       "      <td>4558.1</td>\n",
       "      <td>49.6</td>\n",
       "      <td>16533.5</td>\n",
       "      <td>6656.3</td>\n",
       "      <td>486.2</td>\n",
       "      <td>1156.2</td>\n",
       "      <td>589.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>915.7</td>\n",
       "      <td>1272.1</td>\n",
       "      <td>1068.8</td>\n",
       "      <td>276.6</td>\n",
       "      <td>223.2</td>\n",
       "      <td>161.7</td>\n",
       "      <td>469.3</td>\n",
       "      <td>1213.2</td>\n",
       "      <td>1056.1</td>\n",
       "      <td>55.8</td>\n",
       "      <td>...</td>\n",
       "      <td>45.3</td>\n",
       "      <td>1225.4</td>\n",
       "      <td>884.2</td>\n",
       "      <td>3009.8</td>\n",
       "      <td>2480.2</td>\n",
       "      <td>25535.8</td>\n",
       "      <td>5543.2</td>\n",
       "      <td>256.1</td>\n",
       "      <td>2727.3</td>\n",
       "      <td>2123.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1784.6</td>\n",
       "      <td>465.0</td>\n",
       "      <td>356.4</td>\n",
       "      <td>200.8</td>\n",
       "      <td>118.2</td>\n",
       "      <td>136.2</td>\n",
       "      <td>659.0</td>\n",
       "      <td>995.4</td>\n",
       "      <td>1828.2</td>\n",
       "      <td>174.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>1617.2</td>\n",
       "      <td>2829.1</td>\n",
       "      <td>19.6</td>\n",
       "      <td>13540.0</td>\n",
       "      <td>19490.8</td>\n",
       "      <td>301.1</td>\n",
       "      <td>2104.6</td>\n",
       "      <td>1338.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X226496_at  X219563_at  X208383_s_at  X220082_at  X225809_at  X206339_at  \\\n",
       "0       663.3       517.1       11077.7       429.9       342.0       386.1   \n",
       "1      1747.1       343.6          14.8       181.6       432.2       232.0   \n",
       "2      1738.1      5589.2        4701.2       129.3      1105.4        59.8   \n",
       "3       915.7      1272.1        1068.8       276.6       223.2       161.7   \n",
       "4      1784.6       465.0         356.4       200.8       118.2       136.2   \n",
       "\n",
       "   X227889_at  X210754_s_at  X232964_at  X223609_at      ...       \\\n",
       "0       391.4         588.9      1346.1        82.6      ...        \n",
       "1      1347.7         931.0      1693.5       173.9      ...        \n",
       "2      1007.4        1165.6      1174.5         7.4      ...        \n",
       "3       469.3        1213.2      1056.1        55.8      ...        \n",
       "4       659.0         995.4      1828.2       174.0      ...        \n",
       "\n",
       "   X209987_s_at  X225866_at  X219017_at  X225011_at  X214612_x_at  \\\n",
       "0          24.3      1521.9       581.3      1713.9         137.5   \n",
       "1          88.1      1793.9       661.1      2142.9          46.3   \n",
       "2          12.5      1206.1       705.9      4558.1          49.6   \n",
       "3          45.3      1225.4       884.2      3009.8        2480.2   \n",
       "4           4.9      1407.0      1617.2      2829.1          19.6   \n",
       "\n",
       "   X213699_s_at  X225155_at  X1560500_at  X212337_at  X223206_s_at  \n",
       "0       17556.8      9184.4        648.6      2215.1         593.8  \n",
       "1       19301.6     15380.4       1009.2      2670.4         969.4  \n",
       "2       16533.5      6656.3        486.2      1156.2         589.3  \n",
       "3       25535.8      5543.2        256.1      2727.3        2123.7  \n",
       "4       13540.0     19490.8        301.1      2104.6        1338.4  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the first column from dataframes which are arbitrary\n",
    "train.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "test.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Tissue column to binary\n",
    "train[\"Tissue\"] = train[\"Tissue\"].apply(lambda x: 1 if x == \"Kidney\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X226496_at</th>\n",
       "      <th>X219563_at</th>\n",
       "      <th>X208383_s_at</th>\n",
       "      <th>X220082_at</th>\n",
       "      <th>X225809_at</th>\n",
       "      <th>X206339_at</th>\n",
       "      <th>X227889_at</th>\n",
       "      <th>X210754_s_at</th>\n",
       "      <th>X232964_at</th>\n",
       "      <th>X223609_at</th>\n",
       "      <th>...</th>\n",
       "      <th>X209987_s_at</th>\n",
       "      <th>X225866_at</th>\n",
       "      <th>X219017_at</th>\n",
       "      <th>X225011_at</th>\n",
       "      <th>X214612_x_at</th>\n",
       "      <th>X213699_s_at</th>\n",
       "      <th>X225155_at</th>\n",
       "      <th>X1560500_at</th>\n",
       "      <th>X212337_at</th>\n",
       "      <th>X223206_s_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.311955</td>\n",
       "      <td>0.570401</td>\n",
       "      <td>-0.360641</td>\n",
       "      <td>-0.477985</td>\n",
       "      <td>-0.586033</td>\n",
       "      <td>-0.162167</td>\n",
       "      <td>1.900927</td>\n",
       "      <td>-0.224820</td>\n",
       "      <td>-1.456369</td>\n",
       "      <td>-0.252936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378920</td>\n",
       "      <td>-0.890772</td>\n",
       "      <td>0.812420</td>\n",
       "      <td>-0.187542</td>\n",
       "      <td>-0.207168</td>\n",
       "      <td>-1.228387</td>\n",
       "      <td>-0.312708</td>\n",
       "      <td>-1.095564</td>\n",
       "      <td>-0.071645</td>\n",
       "      <td>0.057597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.589268</td>\n",
       "      <td>-0.716090</td>\n",
       "      <td>-0.263418</td>\n",
       "      <td>-0.429257</td>\n",
       "      <td>-0.207640</td>\n",
       "      <td>-0.121665</td>\n",
       "      <td>-0.200583</td>\n",
       "      <td>1.823334</td>\n",
       "      <td>-0.429771</td>\n",
       "      <td>-0.017315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270445</td>\n",
       "      <td>-0.411486</td>\n",
       "      <td>-0.264420</td>\n",
       "      <td>-0.932667</td>\n",
       "      <td>-0.228798</td>\n",
       "      <td>0.941127</td>\n",
       "      <td>-0.364276</td>\n",
       "      <td>-0.151492</td>\n",
       "      <td>0.603238</td>\n",
       "      <td>0.413250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.856343</td>\n",
       "      <td>-0.910566</td>\n",
       "      <td>-0.271124</td>\n",
       "      <td>4.837861</td>\n",
       "      <td>1.682188</td>\n",
       "      <td>-0.140809</td>\n",
       "      <td>-0.408987</td>\n",
       "      <td>0.971239</td>\n",
       "      <td>-0.701478</td>\n",
       "      <td>-0.130276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407519</td>\n",
       "      <td>1.062259</td>\n",
       "      <td>0.329711</td>\n",
       "      <td>2.921263</td>\n",
       "      <td>-0.250086</td>\n",
       "      <td>0.591574</td>\n",
       "      <td>-0.931114</td>\n",
       "      <td>-0.988940</td>\n",
       "      <td>-0.828754</td>\n",
       "      <td>0.266841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.799742</td>\n",
       "      <td>-0.884409</td>\n",
       "      <td>-0.011917</td>\n",
       "      <td>-0.312511</td>\n",
       "      <td>-0.831881</td>\n",
       "      <td>-0.117053</td>\n",
       "      <td>-0.377324</td>\n",
       "      <td>-0.441309</td>\n",
       "      <td>-0.089803</td>\n",
       "      <td>-0.113745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919810</td>\n",
       "      <td>0.574965</td>\n",
       "      <td>-0.445127</td>\n",
       "      <td>-1.012806</td>\n",
       "      <td>-0.202578</td>\n",
       "      <td>1.980290</td>\n",
       "      <td>3.498522</td>\n",
       "      <td>0.496382</td>\n",
       "      <td>0.552897</td>\n",
       "      <td>-0.746525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118812</td>\n",
       "      <td>-0.281125</td>\n",
       "      <td>6.437190</td>\n",
       "      <td>-0.412551</td>\n",
       "      <td>0.698794</td>\n",
       "      <td>8.981795</td>\n",
       "      <td>-0.818888</td>\n",
       "      <td>-0.880131</td>\n",
       "      <td>0.073489</td>\n",
       "      <td>-0.181302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.498362</td>\n",
       "      <td>-1.018453</td>\n",
       "      <td>-0.265830</td>\n",
       "      <td>1.558394</td>\n",
       "      <td>-0.249891</td>\n",
       "      <td>0.096951</td>\n",
       "      <td>-0.243830</td>\n",
       "      <td>2.911861</td>\n",
       "      <td>-0.503211</td>\n",
       "      <td>-0.571984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X226496_at  X219563_at  X208383_s_at  X220082_at  X225809_at  X206339_at  \\\n",
       "0   -2.311955    0.570401     -0.360641   -0.477985   -0.586033   -0.162167   \n",
       "1   -1.589268   -0.716090     -0.263418   -0.429257   -0.207640   -0.121665   \n",
       "2    0.856343   -0.910566     -0.271124    4.837861    1.682188   -0.140809   \n",
       "3    1.799742   -0.884409     -0.011917   -0.312511   -0.831881   -0.117053   \n",
       "4    0.118812   -0.281125      6.437190   -0.412551    0.698794    8.981795   \n",
       "\n",
       "   X227889_at  X210754_s_at  X232964_at  X223609_at      ...       \\\n",
       "0    1.900927     -0.224820   -1.456369   -0.252936      ...        \n",
       "1   -0.200583      1.823334   -0.429771   -0.017315      ...        \n",
       "2   -0.408987      0.971239   -0.701478   -0.130276      ...        \n",
       "3   -0.377324     -0.441309   -0.089803   -0.113745      ...        \n",
       "4   -0.818888     -0.880131    0.073489   -0.181302      ...        \n",
       "\n",
       "   X209987_s_at  X225866_at  X219017_at  X225011_at  X214612_x_at  \\\n",
       "0     -0.378920   -0.890772    0.812420   -0.187542     -0.207168   \n",
       "1      0.270445   -0.411486   -0.264420   -0.932667     -0.228798   \n",
       "2     -0.407519    1.062259    0.329711    2.921263     -0.250086   \n",
       "3      0.919810    0.574965   -0.445127   -1.012806     -0.202578   \n",
       "4     -0.498362   -1.018453   -0.265830    1.558394     -0.249891   \n",
       "\n",
       "   X213699_s_at  X225155_at  X1560500_at  X212337_at  X223206_s_at  \n",
       "0     -1.228387   -0.312708    -1.095564   -0.071645      0.057597  \n",
       "1      0.941127   -0.364276    -0.151492    0.603238      0.413250  \n",
       "2      0.591574   -0.931114    -0.988940   -0.828754      0.266841  \n",
       "3      1.980290    3.498522     0.496382    0.552897     -0.746525  \n",
       "4      0.096951   -0.243830     2.911861   -0.503211     -0.571984  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard scaling using sklearn (In order to scale down the features to a certain range)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train.drop('Tissue',axis=1))\n",
    "scaled_features = scaler.fit_transform(train.drop('Tissue',axis=1))\n",
    "\n",
    "train_scaled = pd.DataFrame(scaled_features,columns=train.columns[:-1])\n",
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I commented out the below section as it was hard to pull the relevant features from a PCA result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Principal component analysis to drop down the component size to 10 from 50\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=10)\n",
    "# pca.fit(train_scaled)\n",
    "# x_pca = pca.transform(train_scaled)\n",
    "# Check the original shape of the data\n",
    "# train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape after PCA\n",
    "# x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets for evaluation purposes\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = train_scaled\n",
    "y = train[\"Tissue\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "* Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree classification model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90        25\n",
      "          1       0.50      0.40      0.44         5\n",
      "\n",
      "avg / total       0.82      0.83      0.83        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  2]\n",
      " [ 3  2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest classification model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=600)\n",
    "rfc.fit(X_train,y_train)\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        25\n",
      "          1       1.00      0.40      0.57         5\n",
      "\n",
      "avg / total       0.91      0.90      0.88        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0]\n",
      " [ 3  2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model and \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        25\n",
      "          1       1.00      0.60      0.75         5\n",
      "\n",
      "avg / total       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0]\n",
      " [ 2  3]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "* Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False  True  True False  True  True  True False  True\n",
      " False False False False False False False  True  True False False  True\n",
      " False False False False False  True  True  True False  True  True False\n",
      "  True False  True False False False False  True False  True False False\n",
      " False False]\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logmodel, 20)\n",
    "fit = rfe.fit(X, Y)\n",
    "selected_features = fit.support_\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 5, 7, 8, 9, 11, 19, 20, 23, 29, 30, 31, 33, 34, 36, 38, 43, 45]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert the selected features to the index locations\n",
    "def convert(ftr):\n",
    "    list = []\n",
    "    for i in range(len(ftr)):\n",
    "        if (ftr[i] == True):\n",
    "            list.append(i)\n",
    "    print(list)\n",
    "print(convert(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.797e+02 7.856e+01 1.396e+05 1.037e+02 1.702e+03 1.217e+04 5.066e+01\n",
      " 1.343e+03 7.378e+03 2.079e+03 2.913e+03 4.169e+04 6.017e+02 1.025e+01\n",
      " 2.941e+03 3.893e+02 2.016e+03 1.973e+01 8.249e+01 6.907e+02 2.121e+03\n",
      " 3.262e+03 4.230e+01 5.707e+04 1.429e+03 3.586e+03 9.420e+02 3.919e+04\n",
      " 7.132e+02 1.073e+02 2.172e+04 1.008e+04 5.026e+03 4.058e-02 9.906e+03\n",
      " 1.539e+03 2.060e+04 2.477e+01 1.886e+04 8.996e+02 2.100e+02 1.965e+02\n",
      " 2.514e+03 2.913e+03 6.827e+03 2.338e+04 5.478e+00 7.350e+02 4.395e+02\n",
      " 2.025e+03]\n",
      "[[2.780e+01 7.100e+00 2.100e+01 1.397e+03 1.851e+03 1.744e+03 2.362e+02\n",
      "  9.127e+02 9.309e+02 4.217e+03 1.683e+04 3.878e+03 7.290e+03 3.898e+03\n",
      "  6.190e+01 6.662e+03 1.574e+03 2.541e+03 1.079e+02 1.125e+04]\n",
      " [4.492e+02 2.284e+02 7.880e+02 7.704e+02 5.478e+02 1.644e+03 1.400e+03\n",
      "  5.245e+02 1.034e+03 1.761e+04 1.140e+04 2.053e+03 4.252e+03 2.918e+03\n",
      "  3.581e+02 7.282e+03 9.633e+02 1.814e+03 6.360e+01 2.399e+04]\n",
      " [4.158e+02 1.238e+02 5.850e+02 8.872e+03 2.027e+02 2.527e+03 2.049e+02\n",
      "  8.145e+02 1.865e+02 3.469e+03 1.394e+04 1.152e+03 3.247e+03 4.908e+02\n",
      "  1.744e+02 2.655e+04 1.300e+03 5.574e+03 2.000e+01 2.194e+04]\n",
      " [1.539e+03 2.536e+02 1.042e+03 1.027e+03 6.134e+02 2.646e+03 5.276e+02\n",
      "  3.430e+02 2.540e+03 1.468e+04 5.796e+03 9.402e+02 2.639e+03 1.197e+03\n",
      "  2.573e+02 4.085e+03 8.608e+02 1.736e+03 1.173e+02 3.010e+04]\n",
      " [2.949e+04 4.997e+04 1.164e+03 5.669e+03 5.076e+02 2.027e+03 4.461e+02\n",
      "  2.178e+02 1.843e+02 1.889e+03 6.207e+03 4.710e+02 3.820e+03 1.311e+02\n",
      "  4.285e+02 1.050e+03 9.625e+02 4.244e+03 2.040e+01 1.903e+04]]\n"
     ]
    }
   ],
   "source": [
    "# Univariate Selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "X = train.drop('Tissue',axis=1)\n",
    "Y = train[\"Tissue\"]\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=20)\n",
    "fit = test.fit(X, Y)\n",
    "# summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    " * Here I decided to go with Random Forest Classifier model because it provides the highest accuracy for Kidney tissue which is the critical part of this experiment.\n",
    " * Also I decided to keep all the features for this experiment as the sample size is very low.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        25\n",
      "          1       1.00      0.40      0.57         5\n",
      "\n",
      "avg / total       0.91      0.90      0.88        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a random forest classification model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=600)\n",
    "rfc.fit(X_train,y_train)\n",
    "predictions = rfc.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0]\n",
      " [ 3  2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
